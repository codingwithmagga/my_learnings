- Introduction to Big Data
    - Definition of Big Data→Big data is a large, complex data set that cannot be processed using traditional data processing applications.
    - 
    - Name three most common characteristics of Big Data >>>
        - Volume (Large Quantity of Data)
        - Variety (Large variety of unstructured data from multiple sources ⇒ Data fusion necessary)
        - Velocity (Continuous stream of data at a very high rate)
    - 
    - 
- Big Data Processing Strategies
    - Name two strategies/patterns to process big data >>>
        - Batch processing
        - Real-Time processing
    - 
    - Batch processing model
        - Describe→A batch processing model processes large amounts of data in batches at scheduled intervals. The data is often stored in a DFS.
        - Advantages >>>
            - Easy to implement
            - High availability
            - Efficient
            - Higher fault tolerance
            - Complex and in-depth analysis of large datasets
        - Drawback→High latency due to delayed processing.
    - 
    - Real-Time processing
        - Describe→Real-time processing is the immediate analysis of data as it is generated.
        - Advantages→Real-time processing provides immediate insights and enables faster decision-making.
        - Drawbacks >>>
            - Hard to do complex analysis.
            - Doing data-fusion/analyzing historical data is impossible.
- Lambda Architecture
    - Some system need batch and real-time processing of data, like anomaly detection.
    - 
    - Describe→Three layers: A batch layer processing historical data and a speed layer processing real-time data, combined to provide low-latency and high-throughput results. The third layer is the serving layer, which combines the data from the batch and speed layer. 
![](https://remnote-user-data.s3.amazonaws.com/MhGeJHjq4IZEvqcOHqtneIYAzJ5_DtJyHFP7JC2FPqrAee_aTy3iTPah4betLrGdDK-YytusNQMElI7YnCUqhasYXOQTavrmyZpfANMssMulDFhQC7Jghu3gHm-dm_8H.png)
