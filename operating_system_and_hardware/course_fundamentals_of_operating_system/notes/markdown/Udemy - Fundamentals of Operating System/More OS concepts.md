- Compilers and Linkers
    - Machine Code, see also [Assembly Language and Machine Code](../Udemy%20-%20Fundamentals%20of%20Operating%20System/The%20Anatomy%20of%20a%20process/Process%20execution/Assembly%20Language%20and%20Machine%20Code.md)
        - Programs run on machine code
        - Specific to the CPU
        - Each CPU has a different instruction set (RISC vs. CISC)
    - 
    - Assembly, see also [Assembly Language and Machine Code](../Udemy%20-%20Fundamentals%20of%20Operating%20System/The%20Anatomy%20of%20a%20process/Process%20execution/Assembly%20Language%20and%20Machine%20Code.md)
        - Closest to the machine code
        - Still sometimes CPU specific
        - Easier to write
        - Not easy enough though
    - 
    - High-level languages
        - HLL are more convenient
        - Abstractions to hide complexity
        - What does the compiler do? >>>
            - The compiler turns the HLL code to machine code, specific for a CPU architecture (e.g., x86-64).
            - Generates an object file for each translation unit (at least in C++)
            - It optimizes the code for performance and ensures compatibility with the target hardware, allowing the same program to run across different CPUs that support the same instruction set (e.g., Intel and AMD).
        - What does the linker do? >>>
            - The linker is a critical tool in the compilation process that combines multiple object files (generated by the compiler) into a single executable or library. 
            - It resolves references between these files (like function calls) and links them with system libraries (e.g., the C++ standard library) to produce a working program. 
            - Essentially, it "stitches together" all the compiled code so it can run properly.
    - 
    - Executable files formats
        - The executable file is a program
        - Specific format for the OS who knows how to create the process
        - Created by the linker
        - Example ELF Linux, Mach-O Mac and PE (portable executable) Windows
            - ![](https://remnote-user-data.s3.amazonaws.com/hL0zxvmvBSXBnPrfQBF2OACcX2PPb2yKY1E1GwfwIHUrowKplvo60Opa2ow0dsrHzE4rMv09g1-E9fwpfvo3LyCD1AU8DyODrQnyzsXUic2KAGkbsbvkNRBkJx7hOS1R.png)
    - 
    - Interpreted Languages
        - Why does the code run everywhere? >>>
            - Interpreted languages run on a virtual machine, the interpreter, allowing code to run on any system with a compatible virtual machine. 
            - The interpreter acts as a universal middle layer, translating Python byte code into machine-specific instructions at runtime, making it platform-independent as long as the interpreter is available for that system. 
            - For example, in python there is the python runtime containing the interpreter, core libraries and so on and is called for execution:
                - Windows: `python.exe hello.py`
                - Linux: `./python hello.py` 
        - Each line is interpreted ⇒ obviously slower
        - Examples are python, Java and JavaScript
        - Just in Time Compilation
            - Explain how it works >>>
                - Hybrid Approach: Combines interpretation + compilation for speed and portability.
                - Step 1: Interpret First: Code runs via an interpreter (platform-independent).
                - Step 2: Profile Hot Code: Identifies frequently executed parts (e.g., loops).
                - Step 3: Compile Dynamically: Converts hot code to optimized machine code for the host CPU and puts it on the heap.
                - Step 4: Point the CPU program counter to the memory which is marked as executable
                - Result: Faster than pure interpretation, more flexible than static compilation (e.g., Java’s JVM, PyPy, JavaScript’s V8).
    - 
    - Garbage Collection
        - Some languages manage memory for the user: Go, Python, Java
        - How does it work? >>>
            - Part of the runtime
            - Tracks Object Usage: The garbage collector (GC) monitors which objects are still being referenced by active parts of the program.
            - Identifies Garbage: It periodically scans memory to find unreachable objects (no longer referenced by anything).
            - Reclaims Memory: Automatically frees the memory occupied by unused objects, preventing leaks.
            - Slows down the program since CPU time and memory is needed for that task and also the GC needs to ensure that no new reference is created during the cleanup, for example by using a mutex
- Kernel vs. User Mode Switching
    - Kernel vs. User
        - In the process memory space, there is an additional part at the top of each process. What is it?→It's the kernel stack space.
        - The CPU has two modes.→User and Kernel mode
        - What is done in CPU user mode?→The code of the user is executed
        - What is done in Kernel Mode?→The code from the kernel (in the kernel stack) is executed like system calls, drivers etc. 
        - How are the access rights for kernel and user mode in the process memory space for kernel and user space?→In kernel mode, both spaces can be accessed, while in user mode only the user space can be accessed.
        - Describe what happens when the process switch to kernel mode→Almost the same as in a context switch between threads of the same process and when a function is called. The base pointer is stored on the kernel stack, as well as the return address. All registers values and states are stored in memory. 
        - What cost comes with a kernel switch? >>>
            - Mode switch (store all registers and restore them)
            - Memory access
            - Security check and validation
            - System call number lookup (lookup for kernel function place)
- Virtualization and Containerization
    - Multiple native OS
        - Many OS on top of the hardware
        - Switch at startup
        - One active at a time
        - High isolation
        - ![](https://remnote-user-data.s3.amazonaws.com/JRKK6mkE0Yf68Gotdan1toJ4QAN37S4I6uTZZuylcCIZVzX6yjeIp1EvnsbETYYOyEyoeVGGBZW6Q4uZankL8l_VkQ_ErzjluUlU66N_OeO-z_-gsLGnmByMfPkMBbP1.png)
    - 
    - Virtualization
        - Explain the concept >>>
            - Many OSs on top of one base OS
            - Hypervisor (software) controls upper OS
            - Hypervisor  proxies syscalls to lower kernel
            - Full isolation but lots of redundancy
            - ![](https://remnote-user-data.s3.amazonaws.com/lXmLWdbBV1g50m_oCHZWiI3fcDHTn7VM2Z2d9rXo8jX2jH5H31CXmrLyrPhFBKkiWvYDBP9LVcvPviEI8z0ksBltmzZsiGKbk-qe5Uq0rnJBgF2LLr1uY41y4fBAoYnQ.png)
        - E.g. VMWare, Oracle VirtualBox
    - 
    - Containerization
        - Explain the concept >>>
            - Containerization packages apps and dependencies into portable, lightweight containers that run consistently across environments.
            - Efficiency: Unlike VMs, containers share the host OS kernel, reducing overhead and improving performance.
            - Isolation: Linux namespaces (PID, network, mount, etc.) virtualize system resources, keeping containers separated.
            - CPU/Memory usage is limited by cgroups (control groups), kernel feature
            - ![](https://remnote-user-data.s3.amazonaws.com/vzHcpwLs0SQvvJdaNU8h7r5Ru-jf95T_E58n0roQhXQSlvVZ1blg3jlKaes5OdUIBIbcBSIuIbi2xfOlqj5K7W8UoNLZvrDMsK3dM5s7BQggok4BiGoVqshePXjQR7JO.png)
        - E.g. docker or Kubernetes
